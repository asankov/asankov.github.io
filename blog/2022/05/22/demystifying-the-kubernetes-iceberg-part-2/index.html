<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.99.1"><link rel=canonical href=https://asankov.dev/blog/2022/05/22/demystifying-the-kubernetes-iceberg-part-2/><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Demystifying the Kubernetes Iceberg: Part 2 | Anton Sankov's Blog</title><meta name=description content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This article explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><meta property="og:title" content="Demystifying the Kubernetes Iceberg: Part 2"><meta property="og:description" content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This article explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><meta property="og:type" content="article"><meta property="og:url" content="https://asankov.dev/blog/2022/05/22/demystifying-the-kubernetes-iceberg-part-2/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2022-05-22T00:00:00+00:00"><meta property="article:modified_time" content="2022-05-28T21:09:18+03:00"><meta property="og:site_name" content="Anton Sankov's Blog"><meta itemprop=name content="Demystifying the Kubernetes Iceberg: Part 2"><meta itemprop=description content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This article explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><meta itemprop=datePublished content="2022-05-22T00:00:00+00:00"><meta itemprop=dateModified content="2022-05-28T21:09:18+03:00"><meta itemprop=wordCount content="2139"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Demystifying the Kubernetes Iceberg: Part 2"><meta name=twitter:description content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This article explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><link rel=preload href=/scss/main.min.44a19d8ca81d4539a8082ac72051abbde416454636e4b104766b793a69508550.css as=style><link href=/scss/main.min.44a19d8ca81d4539a8082ac72051abbde416454636e4b104766b793a69508550.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7Y9WXX1393"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7Y9WXX1393",{anonymize_ip:!1})}</script></head><body class="td-page td-blog"><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" style=position:relative><a class=navbar-brand href=/><span class=navbar-logo></span><span class="text-uppercase font-weight-bold text-nord5">Anton Sankov's Blog</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/blog/><span class=active>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/about/><span>About Me</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-docs-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-blog-li><a href=/blog/ title="Anton Sankov's Blog" class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-blog><span>Blog</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220529demystifying-the-kubernetes-iceberg-part-3-li><a href=/blog/2022/05/29/demystifying-the-kubernetes-iceberg-part-3/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220529demystifying-the-kubernetes-iceberg-part-3><span>Demystifying the Kubernetes Iceberg: Part 3</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child active-path" id=m-blog20220522demystifying-the-kubernetes-iceberg-part-2-li><a href=/blog/2022/05/22/demystifying-the-kubernetes-iceberg-part-2/ class="align-left pl-0 active td-sidebar-link td-sidebar-link__page" id=m-blog20220522demystifying-the-kubernetes-iceberg-part-2><span class=td-sidebar-nav-active-item>Demystifying the Kubernetes Iceberg: Part 2</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220515demystifying-the-kubernetes-iceberg-part-1-li><a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220515demystifying-the-kubernetes-iceberg-part-1><span>Demystifying the Kubernetes Iceberg: Part 1</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220421securing-kubernetes-with-open-policy-agent-li><a href=/blog/2022/04/21/securing-kubernetes-with-open-policy-agent/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220421securing-kubernetes-with-open-policy-agent><span>Securing Kubernetes with Open Policy Agent</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220129different-ways-to-initialize-go-structs-li><a href=/blog/2022/01/29/different-ways-to-initialize-go-structs/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220129different-ways-to-initialize-go-structs><span>Different Ways to Initialize Go structs</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#tier-3>Tier 3</a><ul><li><a href=#crd>CRD</a></li><li><a href=#persistentvolumeclaim>PersistentVolumeClaim</a></li><li><a href=#statefulset>StatefulSet</a></li><li><a href=#helm-templating>Helm templating</a></li><li><a href=#dashboard>Dashboard</a></li><li><a href=#hpa>HPA</a></li><li><a href=#log-management>Log management</a></li><li><a href=#init-containers>Init containers</a></li><li><a href=#affinity>Affinity</a></li><li><a href=#taints-and-tolerations>Taints and Tolerations</a></li><li><a href=#resourcelimitshttpskubernetesiodocsconceptsconfigurationmanage-resources-containers><a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>ResourceLimits</a></a></li></ul></li><li><a href=#summary>Summary</a></li></ul></nav></div><div class="taxonomy taxonomy-terms-cloud taxo-categories"><h5 class=taxonomy-title>Categories</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://asankov.dev/categories/gatekeeper/ data-taxonomy-term=gatekeeper><span class=taxonomy-label>Gatekeeper</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/go/ data-taxonomy-term=go><span class=taxonomy-label>Go</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/kubernetes/ data-taxonomy-term=kubernetes><span class=taxonomy-label>Kubernetes</span><span class=taxonomy-count>4</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/open-policy-agent/ data-taxonomy-term=open-policy-agent><span class=taxonomy-label>Open Policy Agent</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/security/ data-taxonomy-term=security><span class=taxonomy-label>Security</span><span class=taxonomy-count>1</span></a></li></ul></div></aside><main class="col-12 col-md-9 col-xl-8 pl-md-5 pr-md-4" role=main><div class=td-content><h1>Demystifying the Kubernetes Iceberg: Part 2</h1><div class=lead>Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This article explains all the concepts listed in the &ldquo;Kubernetes Iceberg&rdquo; meme by Flant.</div><div class="td-byline mb-4"><time datetime=2022-05-22 class=text-muted>Sunday, May 22, 2022</time></div><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-categories"><h5 class=taxonomy-title>Categories:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://asankov.dev/categories/kubernetes/ data-taxonomy-term=kubernetes><span class=taxonomy-label>Kubernetes</span></a></li></ul></div><p class=reading-time><i class="fa fa-clock" aria-hidden=true></i>&nbsp; 11 minute read &nbsp;</p></header><p>This is the second article of the &ldquo;Demystifying the Kubernetes Iceberg&rdquo; series.
My goal for this series is to explain all concepts mentioned in the “Kubernetes Iceberg” meme by <a href=https://flant.com/>Flant</a>.</p><p>You can find the first article <a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/>here</a>.
I will publish one article each week until I complete the whole iceberg.</p><p>And this is the iceberg itself:</p><p><img src=/images/kubernetes-iceberg.png alt="The Kubernetes Iceberg meme"></p><p>In this article, I focus on Tier 3 of the Iceberg.
Let’s go!</p><h2 id=tier-3>Tier 3</h2><h3 id=crd>CRD</h3><p><code>CRD</code> or a <a href=https://kubernetes.io/docs/concepts/extend-kubernetes/api-extension/custom-resources/><code>Custom Resource Definition</code></a> is a way to extend the Kubernetes API by adding your own resource.</p><p>You can define what fields it has, what types they are, whether any of them is required, their default values, etc.</p><p>Kubernetes will register CRUD API endpoints for this resource (get, list, watch, delete, etc.) and you can start treating this resource as any of the Kubernetes build-in ones (Pods, Deployments, etc.).</p><p>This includes:</p><ul><li>using <code>kubectl</code> to <code>get</code> or <code>describe</code> this resource</li><li>creating instances of this resource via YAML files and <code>kubectl apply</code></li><li>calling the REST APIs for this resource directly, e.g. <code>curl &lt;kube_url>/api/&lt;version>/&lt;crd_name></code></li></ul><p>If you want to have an additional logic around your resource, e.g. trigger some actions when someone creates an instance of our CRD, you can do that by implementing an operator (more on that in later posts).</p><p>You can check out my <a href="(https://www.youtube.com/watch?v=yim8NnYjODY)">presentation</a> from ISTA 2021 about how to use CRD to build a CRUD application backend.</p><h3 id=persistentvolumeclaim>PersistentVolumeClaim</h3><p>A <code>PersistentVolumeClaim</code> is a request for storage by a user/resource.
The given storage is taken from a <a href=https://kubernetes.io/docs/concepts/storage/persistent-volumes/><code>PersistentVolume</code></a>, which is an abstract Kubernetes object that represents some storage.
There are different storage classes, that represent the different implementations of storage that can be used by Kubernetes.
The storage class is specified in the <code>PersistentVolume</code> spec.</p><p>Once a <code>PersistentVolumeClaim</code> is created, Kubernetes will try to utilize the storage by provisioning the requested amount to the requester.</p><p>The <code>PersistentVolumeClaim</code> also specified the access mode to the storage (e.g. <code>ReadWriteOnce</code>, <code>ReadOnlyMany</code>, or <code>ReadWriteMany</code>).</p><h3 id=statefulset>StatefulSet</h3><p>A <a href=https://kubernetes.io/docs/concepts/workloads/controllers/statefulset/><code>StatefulSet</code></a> is a Kubernetes resource the represents a workload.
It is similar to a <a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/#deployments><code>Deployment</code></a> - it manages a set of Pods based on a Pod spec.
The specific thing about a <code>StatefulSet</code> is that manages stateful applications (hence the name).</p><p>It is useful for situations where you want:</p><ul><li>stable, unique network identifiers</li><li>stable, persistent storage</li><li>ordered, graceful deployment and scaling</li><li>ordered, automatic rolling updates</li></ul><h3 id=helm-templating>Helm templating</h3><p><a href=https://helm.sh/>Helm</a> is a templating engine that allows you to write reusable Kubernetes templates.</p><p>For example, if you have a Pod that you deploy to three environments and you want to set a different label for each environment, you don&rsquo;t need to copy-paste the Pod YAML three times and just change the value of the label.</p><p>You can use Helm to extract the different fields into variables, which later get templated, and reuse all the parts that don&rsquo;t differ between environments.</p><p>For example, this is a template for a Pod with a hardcoded <code>environment</code> label:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#268bd2>apiVersion</span>: v1
</span></span><span style=display:flex><span><span style=color:#268bd2>kind</span>: Pod
</span></span><span style=display:flex><span><span style=color:#268bd2>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>name</span>: busybox-sleep
</span></span><span style=display:flex><span>  <span style=color:#268bd2>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#268bd2>environment</span>: production
</span></span><span style=display:flex><span><span style=color:#268bd2>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#268bd2>name</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>image</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>args</span>:
</span></span><span style=display:flex><span>        - sleep
</span></span><span style=display:flex><span>        - <span style=color:#2aa198>&#34;1000000&#34;</span>
</span></span></code></pre></div><p>If we want to convert this to a Helm template all we need to do is:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#268bd2>apiVersion</span>: v1
</span></span><span style=display:flex><span><span style=color:#268bd2>kind</span>: Pod
</span></span><span style=display:flex><span><span style=color:#268bd2>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>name</span>: busybox-sleep
</span></span><span style=display:flex><span>  <span style=color:#268bd2>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#268bd2>environment</span>: {{ .Values.environment }}
</span></span><span style=display:flex><span><span style=color:#268bd2>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#268bd2>name</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>image</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>args</span>:
</span></span><span style=display:flex><span>        - sleep
</span></span><span style=display:flex><span>        - <span style=color:#2aa198>&#34;1000000&#34;</span>
</span></span></code></pre></div><p>Now the value of the <code>environment</code> label comes from the <code>.Values.environment</code> variable.</p><p>This variable comes from a so-called values file.</p><p>This is a YAML in which we specify the values of our variables.</p><p>By using different values files we can output different resource specs with different values.</p><p>For example, we can have one values files for each of our environments:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#586e75># dev.yaml</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>environment</span>: dev
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#586e75># staging.yaml</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>environment</span>: staging
</span></span></code></pre></div><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#586e75># production.yaml</span>
</span></span><span style=display:flex><span><span style=color:#268bd2>environment</span>: production
</span></span></code></pre></div><p>Using the template shown above with the <code>dev.yaml</code> values file will output this spec:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#268bd2>apiVersion</span>: v1
</span></span><span style=display:flex><span><span style=color:#268bd2>kind</span>: Pod
</span></span><span style=display:flex><span><span style=color:#268bd2>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>name</span>: busybox-sleep
</span></span><span style=display:flex><span>  <span style=color:#268bd2>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#268bd2>environment</span>: dev
</span></span><span style=display:flex><span><span style=color:#268bd2>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#268bd2>name</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>image</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>args</span>:
</span></span><span style=display:flex><span>        - sleep
</span></span><span style=display:flex><span>        - <span style=color:#2aa198>&#34;1000000&#34;</span>
</span></span></code></pre></div><p>While using it with the <code>production.yaml</code> values file will output this one:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#268bd2>apiVersion</span>: v1
</span></span><span style=display:flex><span><span style=color:#268bd2>kind</span>: Pod
</span></span><span style=display:flex><span><span style=color:#268bd2>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>name</span>: busybox-sleep
</span></span><span style=display:flex><span>  <span style=color:#268bd2>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#268bd2>environment</span>: production
</span></span><span style=display:flex><span><span style=color:#268bd2>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#268bd2>name</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>image</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>args</span>:
</span></span><span style=display:flex><span>        - sleep
</span></span><span style=display:flex><span>        - <span style=color:#2aa198>&#34;1000000&#34;</span>
</span></span></code></pre></div><h4 id=package-manager>Package manager</h4><p>Apart from a templating engine, Helm is also a package manager for Kubernetes.
You can use it to &ldquo;package&rdquo; your Helm charts (a Helm chart == a bunch of templates) and publish them into a repository.
Once you do that, everyone can install you chart into their cluster via the <code>helm install</code> command and use Helm to manage the lifecycle of that chart.</p><h3 id=dashboard>Dashboard</h3><p>A dashboard is a type of graphical user interface which provides visual information about some metrics in a given system.</p><p>A Kubernetes dashboard would show the number of Pods, Deployment, Services, Nodes, etc.</p><p>There is an “official” dashboard provided by Kubernetes, which you can install in your cluster.
It is a web-based one, that shows you all the resources in your cluster and a lot of other useful information. It looks like this:</p><p><img src=/images/kubernetes-dashboard.png alt="Screenshot from the Kubernetes dashboard application">
<a href=https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/>Source of the image</a></p><p>To install it, you need to apply some Kubernetes resource and expose them outside of the cluster (so that you can open the web page in your browser).</p><p>More information about the dashboard, and how to install it you can find <a href=https://kubernetes.io/docs/tasks/access-application-cluster/web-ui-dashboard/>here</a>.</p><p>Apart from this “official” dashboard there are other open-source projects which you can use to get the same information.
They are called Kubernetes IDEs and they provide similar experience to the Kubernetes dashboard.</p><p>Some of them are:</p><h4 id=k9shttpsk9scliio><a href=https://k9scli.io/>K9s</a></h4><p>Open-source CLI-based Kubernetes IDE.
Connects to the cluster(s) defined in your kubeconfig file.</p><p>Good for users that prefer the terminal.
Supports many “power-user” workflows.</p><p><img src=/images/k9s.png alt="Screenshot from the K9s application"></p><h4 id=lenshttpsk8slensdev><a href=https://k8slens.dev/>Lens</a></h4><p>Open-source Desktop application based on Electron.</p><p>Build by the Lens team, now part of <a href=https://www.mirantis.com/>Mirantis</a>.
Supports adding multiple Kubernetes clusters and switching between them.</p><p><img src=/images/lens.png alt="Screenshot from the Lens application"></p><h4 id=octanthttpsoctantdev><a href=https://octant.dev/>Octant</a></h4><p>Open-source Web-based dashboard, by <a href=https://www.vmware.com/>VMware</a>.</p><p>Can be run locally or deployed into a remote cluster and accessed via the browser.</p><p><img src=/images/octant.png alt="Screenshot from the Octant application"></p><h3 id=hpa>HPA</h3><p>HPA or <a href=https://kubernetes.io/docs/tasks/run-application/horizontal-pod-autoscale/><code>HorizontalPodAutoscaler</code></a> is a Kube API server feature that allows you to scale workloads horizontally based on metrics.</p><p>Horizontal scaling means that we are increasing the count of the running workloads (e.g. go from 3 Pods to 5).
This is different than vertical scaling, which means increasing the resources on a given workloads (e.g. increase the CPU and memory provided to a Pod).</p><p>The <code>HorizontalPodAutoscaler</code> is created as a Kubernetes resource, part of the <code>autoscaling</code> API group.
It defines the workloads selector and the metrics based on which we’ll do the scaling.
Once on every interval (that is defined by the user, with a default value) the Kube API server will query the metrics of the Pods, and based on the conditions we defined will decide whether it needs to scale the workloads up (more pods) or down (less pods).</p><p>There is always a min and max Pod count, e.g. never go below a certain number of Pods, and never go above a certain number of Pods.</p><p>There are some default metrics that are defined by Kubernetes that can be used with <code>HorizontalPodAutoscaler</code> out of the box, but there is also a capability to use it with custom metrics, defined by you (more on that in the next article).</p><h3 id=log-management>Log management</h3><p>When running containers, they are usually configured to output their logs to <code>stdout</code> and <code>stderr</code> (at least, this is the best practice).
If the container dies (because of an issue or because we are upgrading the application), the logs will be lost (because the two output streams will go away with the container).</p><p>This means that we need to plug in something else that will read these logs and store them permanently in a way not tied to the container lifecycle.</p><p>Fortunately, Kubernetes has a solution for this.
It supports a lot of log drivers, which can be integrated with your application logging (without having custom logic in your app).
These drivers will read data from the container output streams and send the logs to a centralized system like <a href=https://logz.io/>logz.io</a>, <a href=https://www.splunk.com/>Splunk</a>, or <a href=https://grafana.com/oss/loki/>Loki</a>.
Once there your logs are safe and they will not be lost, even if a container dies.
Also, a lot of these systems provide an easy way to aggregate logs from different services and search through the logs based on a keyword, or field-based search (if you have structured logging).</p><h3 id=init-containers>Init containers</h3><p>Init containers are specialized containers that run before app containers in a Pod.</p><p>They can be used to execute some actions in the Pod to prepare the Pod for the execution of the main container.</p><p>You can have multiple init containers in a Pod. Kubernetes will run all of them before running the main container.</p><p>All init containers need to exit successfully for Kubernetes to start the main container. If an init container fails, Kubernetes will restart it</p><p>You can specify init containers via the <code>spec.initContainers</code> field in the Pod spec.</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#268bd2>apiVersion</span>: v1
</span></span><span style=display:flex><span><span style=color:#268bd2>kind</span>: Pod
</span></span><span style=display:flex><span><span style=color:#268bd2>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>name</span>: my-app-pod
</span></span><span style=display:flex><span>  <span style=color:#268bd2>labels</span>:
</span></span><span style=display:flex><span>    <span style=color:#268bd2>app</span>: my-app
</span></span><span style=display:flex><span><span style=color:#268bd2>spec</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>containers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#268bd2>name</span>: my-app-container
</span></span><span style=display:flex><span>      <span style=color:#268bd2>image</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#268bd2>command</span>: [<span style=color:#2aa198>&#34;sh&#34;</span>, <span style=color:#2aa198>&#34;-c&#34;</span>, <span style=color:#2aa198>&#34;echo The app is running! &amp;&amp; sleep 3600&#34;</span>]
</span></span><span style=display:flex><span>  <span style=color:#268bd2>initContainers</span>:
</span></span><span style=display:flex><span>    - <span style=color:#268bd2>name</span>: my-app-first-init-container
</span></span><span style=display:flex><span>      <span style=color:#268bd2>image</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#586e75># print &#34;Hello from init container 1&#34; 5 times then exit successfully</span>
</span></span><span style=display:flex><span>      <span style=color:#268bd2>command</span>:
</span></span><span style=display:flex><span>        [
</span></span><span style=display:flex><span>          <span style=color:#2aa198>&#34;sh&#34;</span>,
</span></span><span style=display:flex><span>          <span style=color:#2aa198>&#34;-c&#34;</span>,
</span></span><span style=display:flex><span>          <span style=color:#2aa198>&#34;for i in {1..5}; do echo &#39;Hello from init container 1&#39;; done; exit 0&#34;</span>,
</span></span><span style=display:flex><span>        ]
</span></span><span style=display:flex><span>    - <span style=color:#268bd2>name</span>: my-app-second-init-container
</span></span><span style=display:flex><span>      <span style=color:#268bd2>image</span>: busybox
</span></span><span style=display:flex><span>      <span style=color:#586e75># print &#34;Hello from init container 1&#34; 10 times then exit successfully</span>
</span></span><span style=display:flex><span>      <span style=color:#268bd2>command</span>:
</span></span><span style=display:flex><span>        [
</span></span><span style=display:flex><span>          <span style=color:#2aa198>&#34;sh&#34;</span>,
</span></span><span style=display:flex><span>          <span style=color:#2aa198>&#34;-c&#34;</span>,
</span></span><span style=display:flex><span>          <span style=color:#2aa198>&#34;for i in {1..10}; do echo &#39;Hello from init container 2&#39;; done; exit 0&#34;</span>,
</span></span><span style=display:flex><span>        ]
</span></span></code></pre></div><h3 id=affinity>Affinity</h3><p><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/assign-pod-node/>Affinity</a> is the capability to specify the preferred nodes for a workload, e.g. a workload has <strong>affinity</strong> towards a node.</p><p>You can do that by setting labels on the Nodes, and then setting the affinity towards these labels in the Pod spec of the workloads.</p><h3 id=taints-and-tolerations>Taints and Tolerations</h3><p><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/taint-and-toleration/>Taints and Tolerations</a> are the opposite of Affinity.
Whilst the affinity defines the preferred Nodes for a Pod, Taints and Tolerations define the opposite - Nodes, where the Pods should NOT be scheduled on.</p><p>Each Node can have multiple taints.
In order for a Pod to be able to be scheduled on a Node, a Pod must have Tolerations for all the Taints on that Node.</p><h4 id=effects>Effects</h4><p>Taints/Tolerations can have different effects, which mean different things:</p><ul><li><code>NoSchedule</code> - if a Pod does not have a matching Toleration, Kubernetes will not schedule it on that Node. The Pod will keep running, if it was scheduled, before the Taints was added.</li><li><code>PreferNoSchedule</code> - if a Pod does not have a matching Toleration, Kubernetes will <em>try to</em> not schedule it on that Node, but it will, if it has no other available Nodes. The Pod will keep running, if it was scheduled, before the Taints was added.</li><li><code>NoExecute</code> - if a Pod does not have a matching Toleration, Kubernetes will not schedule it on that Node. If the Pod is already running on the Node, Kubernetes will evict it and re-schedule it on a new Node.</li></ul><h4 id=use-cases>Use-cases</h4><p>Some use-cases for Taints are Tolerations are:</p><ul><li>dedicated nodes - if you have different types of nodes, dedicated for different workloads in the same cluster, you can use Taints and Tolerations to make sure each Pods are scheduled on the right nodes.</li><li>nodes with special hardware - if you a set of nodes that have some special hardware (for example, GPUs) you can use Taints and Tolerations to make sure that only the Pods that need that hardware are scheduled on these nodes</li><li>eviction - you can implement a logic that adds a <code>NoExecute</code> taints on a Node if certain conditions are met.
This will evict all Pods from that Node and reschedule them on different Nodes.
Kubernetes uses Taints with the <code>NoExecute</code> effect to make sure that no Pods are scheduled on Nodes that are consider not ready or have some sort of hardware issues (disk, CPU) or networking problems (unreachable nodes, etc.)
Also, if you want to remove a Node, you can add a <code>NoExecute</code> taint before actually removing the Node, to ensure a smooth transition of all Pods to the other Nodes.</li></ul><h3 id=resourcelimitshttpskubernetesiodocsconceptsconfigurationmanage-resources-containers><a href=https://kubernetes.io/docs/concepts/configuration/manage-resources-containers/>ResourceLimits</a></h3><p>For each Pod, you can specify how many resources a container needs (requests) and what is the maximum (limit) that the container can get.</p><p>The Kube scheduler will use the information from <code>requests</code> when scheduling a Pod onto a Node.</p><p>The Kubelet will enforce that no container gets more resources than its <code>limit</code>.</p><p>Specifying Resource limits in Kubernetes is optional but highly advisable. If you don’t set resource limits for a container and that container has a problem like a memory leak, it will use all the Node&rsquo;s memory and starve all other workloads on that Node out of memory.</p><h2 id=summary>Summary</h2><p>This is all for part two.
I hope you enjoyed it and learned something new.</p><p>The series continues with <a href=/blog/2022/05/29/demystifying-the-kubernetes-iceberg-part-3/>Part 3</a>.</p><p>If you don’t want to miss it, you can follow me on <a href=https://twitter.com/a_sankov>Twitter</a> or <a href=https://www.linkedin.com/in/asankov/>LinkedIn</a>.</p><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/ aria-label="Previous - Demystifying the Kubernetes Iceberg: Part 1" class="btn btn-primary"><span class=mr-1>←</span>Previous</a></li><a href=/blog/2022/05/29/demystifying-the-kubernetes-iceberg-part-3/ aria-label="Next - Demystifying the Kubernetes Iceberg: Part 3" class="btn btn-primary">Next<span class=ml-1>→</span></a></li></ul></div></main></div></div><footer class="py-5 row d-print-none bg-nord0"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank rel=noopener href=mailto:asankov96@gmail.com aria-label="User mailing list"><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/a_sankov aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/asankov aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=LinkedIn aria-label=LinkedIn><a class=text-white target=_blank rel=noopener href=https://linkedin.com/in/asankov aria-label=LinkedIn><i class="fab fa-linkedin"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2022 Anton Sankov All Rights Reserved</small>
<small class=ml-1><a href=https://policies.google.com/privacy target=_blank rel=noopener>Privacy Policy</a></small><p class=mt-2><a href=/about/>About Me</a></p></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.c0aaf80cdc7e96409841d851962b8c4caed4c9ebeb0e11edd617370f61f99727.js integrity="sha256-wKr4DNx+lkCYQdhRliuMTK7UyevrDhHt1hc3D2H5lyc=" crossorigin=anonymous></script></body></html>