<!doctype html><html lang=en class=no-js><head><meta charset=utf-8><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=generator content="Hugo 0.101.0"><link rel=canonical href=https://asankov.dev/blog/2022/05/29/demystifying-the-kubernetes-iceberg-part-3/><meta name=robots content="index, follow"><link rel="shortcut icon" href=/favicons/favicon.ico><link rel=apple-touch-icon href=/favicons/apple-touch-icon-180x180.png sizes=180x180><link rel=icon type=image/png href=/favicons/favicon-16x16.png sizes=16x16><link rel=icon type=image/png href=/favicons/favicon-32x32.png sizes=32x32><link rel=icon type=image/png href=/favicons/android-36x36.png sizes=36x36><link rel=icon type=image/png href=/favicons/android-48x48.png sizes=48x48><link rel=icon type=image/png href=/favicons/android-72x72.png sizes=72x72><link rel=icon type=image/png href=/favicons/android-96x96.png sizes=96x96><link rel=icon type=image/png href=/favicons/android-144x144.png sizes=144x144><link rel=icon type=image/png href=/favicons/android-192x192.png sizes=192x192><title>Demystifying the Kubernetes Iceberg: Part 3 | Anton Sankov's Blog</title><meta name=description content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This series of articles explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><meta property="og:title" content="Demystifying the Kubernetes Iceberg: Part 3"><meta property="og:description" content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This series of articles explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><meta property="og:type" content="article"><meta property="og:url" content="https://asankov.dev/blog/2022/05/29/demystifying-the-kubernetes-iceberg-part-3/"><meta property="article:section" content="blog"><meta property="article:published_time" content="2022-05-29T00:00:00+00:00"><meta property="article:modified_time" content="2022-06-19T09:45:31+02:00"><meta property="og:site_name" content="Anton Sankov's Blog"><meta itemprop=name content="Demystifying the Kubernetes Iceberg: Part 3"><meta itemprop=description content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This series of articles explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><meta itemprop=datePublished content="2022-05-29T00:00:00+00:00"><meta itemprop=dateModified content="2022-06-19T09:45:31+02:00"><meta itemprop=wordCount content="2220"><meta itemprop=keywords content><meta name=twitter:card content="summary"><meta name=twitter:title content="Demystifying the Kubernetes Iceberg: Part 3"><meta name=twitter:description content="Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This series of articles explains all the concepts listed in the &#34;Kubernetes Iceberg&#34; meme by Flant.
"><link rel=preload href=/scss/main.min.2022a913c80b8b832ae4a6e4e95fb0a9f79c4a67af49994e93727f83e11d0b33.css as=style><link href=/scss/main.min.2022a913c80b8b832ae4a6e4e95fb0a9f79c4a67af49994e93727f83e11d0b33.css rel=stylesheet integrity><script src=https://code.jquery.com/jquery-3.5.1.min.js integrity="sha256-9/aliU8dGd2tb6OSsuzixeV4y/faTqgFtohetphbbj0=" crossorigin=anonymous></script>
<script async src="https://www.googletagmanager.com/gtag/js?id=G-7Y9WXX1393"></script>
<script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-7Y9WXX1393",{anonymize_ip:!1})}</script></head><body class="td-page td-blog"><header><nav class="js-navbar-scroll navbar navbar-expand navbar-dark flex-column flex-md-row td-navbar" style=position:relative><a class=navbar-brand href=/><span class=navbar-logo></span><span class="text-uppercase font-weight-bold text-nord5">Anton Sankov's Blog</span></a><div class="td-navbar-nav-scroll ml-md-auto" id=main_navbar><ul class="navbar-nav mt-2 mt-lg-0"><li class="nav-item mr-4 mb-2 mb-lg-0"><a class="nav-link active" href=/blog/><span class=active>Blog</span></a></li><li class="nav-item mr-4 mb-2 mb-lg-0"><a class=nav-link href=/about/><span>About Me</span></a></li></ul></div><div class="navbar-nav d-none d-lg-block"></div></nav></header><div class="container-fluid td-outer"><div class=td-main><div class="row flex-xl-nowrap"><aside class="col-12 col-md-3 col-xl-2 td-sidebar d-print-none"><div id=td-sidebar-menu class=td-sidebar__inner><form class="td-sidebar__search d-flex align-items-center"><button class="btn btn-link td-sidebar__toggle d-md-none p-0 ml-3 fas fa-bars" type=button data-toggle=collapse data-target=#td-section-nav aria-controls=td-docs-nav aria-expanded=false aria-label="Toggle section navigation"></button></form><nav class="collapse td-sidebar-nav" id=td-section-nav><ul class="td-sidebar-nav__section pr-md-3 ul-0"><li class="td-sidebar-nav__section-title td-sidebar-nav__section with-child active-path" id=m-blog-li><a href=/blog/ title="Anton Sankov's Blog" class="align-left pl-0 td-sidebar-link td-sidebar-link__section tree-root" id=m-blog><span>Blog</span></a><ul class=ul-1><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220704demystifying-the-kubernetes-iceberg-part-7-li><a href=/blog/2022/07/04/demystifying-the-kubernetes-iceberg-part-7/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220704demystifying-the-kubernetes-iceberg-part-7><span>Demystifying the Kubernetes Iceberg: Part 7</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220627demystifying-the-kubernetes-iceberg-part-6-li><a href=/blog/2022/06/27/demystifying-the-kubernetes-iceberg-part-6/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220627demystifying-the-kubernetes-iceberg-part-6><span>Demystifying the Kubernetes Iceberg: Part 6</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220612demystifying-the-kubernetes-iceberg-part-5-li><a href=/blog/2022/06/12/demystifying-the-kubernetes-iceberg-part-5/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220612demystifying-the-kubernetes-iceberg-part-5><span>Demystifying the Kubernetes Iceberg: Part 5</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220605demystifying-the-kubernetes-iceberg-part-4-li><a href=/blog/2022/06/05/demystifying-the-kubernetes-iceberg-part-4/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220605demystifying-the-kubernetes-iceberg-part-4><span>Demystifying the Kubernetes Iceberg: Part 4</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220529demystifying-the-kubernetes-iceberg-part-3-li><a href=/blog/2022/05/29/demystifying-the-kubernetes-iceberg-part-3/ class="align-left pl-0 active td-sidebar-link td-sidebar-link__page" id=m-blog20220529demystifying-the-kubernetes-iceberg-part-3><span class=td-sidebar-nav-active-item>Demystifying the Kubernetes Iceberg: Part 3</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220522demystifying-the-kubernetes-iceberg-part-2-li><a href=/blog/2022/05/22/demystifying-the-kubernetes-iceberg-part-2/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220522demystifying-the-kubernetes-iceberg-part-2><span>Demystifying the Kubernetes Iceberg: Part 2</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220515demystifying-the-kubernetes-iceberg-part-1-li><a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220515demystifying-the-kubernetes-iceberg-part-1><span>Demystifying the Kubernetes Iceberg: Part 1</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220421securing-kubernetes-with-open-policy-agent-li><a href=/blog/2022/04/21/securing-kubernetes-with-open-policy-agent/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220421securing-kubernetes-with-open-policy-agent><span>Securing Kubernetes with Open Policy Agent</span></a></li><li class="td-sidebar-nav__section-title td-sidebar-nav__section without-child" id=m-blog20220129different-ways-to-initialize-go-structs-li><a href=/blog/2022/01/29/different-ways-to-initialize-go-structs/ class="align-left pl-0 td-sidebar-link td-sidebar-link__page" id=m-blog20220129different-ways-to-initialize-go-structs><span>Different Ways to Initialize Go structs</span></a></li></ul></li></ul></nav></div></aside><aside class="d-none d-xl-block col-xl-2 td-sidebar-toc d-print-none"><div class="td-page-meta ml-2 pb-1 pt-2 mb-0"></div><div class=td-toc><nav id=TableOfContents><ul><li><a href=#tier-4>Tier 4</a><ul><li><a href=#load-balancing>Load Balancing</a></li><li><a href=#service-discovery>Service Discovery</a></li><li><a href=#pid-namespace-sharinghttpskubernetesiodocstasksconfigure-pod-containershare-process-namespace><a href=https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/>PID namespace sharing</a></a></li><li><a href=#hard-and-soft-evictions>Hard and Soft Evictions</a></li><li><a href=#evictions-api-pdbhttpskubernetesiodocsconceptsscheduling-evictionapi-eviction><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/api-eviction/>Evictions API (PDB)</a></a></li><li><a href=#prometheus>Prometheus</a></li><li><a href=#grafana>Grafana</a></li><li><a href=#promql>PromQL</a></li><li><a href=#health-checks>Health checks</a></li><li><a href=#terraform>Terraform</a></li><li><a href=#qos-cgroups-oom_score_adj>QoS (cgroups, oom_score_adj)</a></li><li><a href=#hpavpa-based-on-custom-metrics>HPA/VPA based on custom metrics</a></li></ul></li><li><a href=#summary>Summary</a></li></ul></nav></div><div class="taxonomy taxonomy-terms-cloud taxo-categories"><h5 class=taxonomy-title>Categories</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://asankov.dev/categories/gatekeeper/ data-taxonomy-term=gatekeeper><span class=taxonomy-label>Gatekeeper</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/go/ data-taxonomy-term=go><span class=taxonomy-label>Go</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/kubernetes/ data-taxonomy-term=kubernetes><span class=taxonomy-label>Kubernetes</span><span class=taxonomy-count>8</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/open-policy-agent/ data-taxonomy-term=open-policy-agent><span class=taxonomy-label>Open Policy Agent</span><span class=taxonomy-count>1</span></a></li><li><a class=taxonomy-term href=https://asankov.dev/categories/security/ data-taxonomy-term=security><span class=taxonomy-label>Security</span><span class=taxonomy-count>2</span></a></li></ul></div></aside><main class="col-12 col-md-9 col-xl-8 pl-md-5 pr-md-4" role=main><div class=td-content><h1>Demystifying the Kubernetes Iceberg: Part 3</h1><div class=lead>Kubernetes is like an iceberg. You learn the basics, only to see there is a lot more to learn. The more you learn, the more you see there is to know. This series of articles explains all the concepts listed in the &ldquo;Kubernetes Iceberg&rdquo; meme by Flant.</div><div class="td-byline mb-4"><time datetime=2022-05-29 class=text-muted>Sunday, May 29, 2022</time></div><header class=article-meta><div class="taxonomy taxonomy-terms-article taxo-categories"><h5 class=taxonomy-title>Categories:</h5><ul class=taxonomy-terms><li><a class=taxonomy-term href=https://asankov.dev/categories/kubernetes/ data-taxonomy-term=kubernetes><span class=taxonomy-label>Kubernetes</span></a></li></ul></div><p class=reading-time><i class="fa fa-clock" aria-hidden=true></i>&nbsp; 11 minute read &nbsp;</p></header><p>This is the third article of the &ldquo;Demystifying the Kubernetes Iceberg&rdquo; series.
My goal for this series is to explain all concepts mentioned in the “Kubernetes Iceberg” meme by <a href=https://flant.com/>Flant</a>.</p><p>You can find the first article <a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/>here</a> and the second one - <a href=/blog/2022/05/22/demystifying-the-kubernetes-iceberg-part-2/>here</a>.
I will publish one article each week until I complete the whole iceberg.</p><p>And this is the iceberg itself:</p><p><img src=/images/kubernetes-iceberg.png alt="The Kubernetes Iceberg meme"></p><p>In this article, I focus on Tier 4 of the Iceberg.
Let’s go!</p><h2 id=tier-4>Tier 4</h2><h3 id=load-balancing>Load Balancing</h3><p>Load Balancing as a concept means that you have multiple instances of a given workload, but you don&rsquo;t access them directly.
Instead, you access a load balancer/gateway/reverse proxy that decides which instance of your workload to call.</p><p>In Kubernetes, the same concept can be applied to Pods and Services.</p><p>In <a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/>Tier 1</a>, I explained how <a href=/blog/2022/05/15/demystifying-the-kubernetes-iceberg-part-1/#service>Services</a> provide stable IP and networking to Pods that are ephemeral and can be replaced with other Pods (with different IPs) at any given time.</p><p>Services also provide Load Balancing between these Pods.
A Service that represents 3 Pods will route traffic to these pods on a round-robin basis.</p><h3 id=service-discovery>Service Discovery</h3><p>Service Discovery is the way services in a micro-services architecture discover one another.</p><p>Outside of Kubernetes, a popular tool for service discovery is <a href=https://github.com/spring-cloud/spring-cloud-netflix>Eureka</a>.
It allows services to register themselves and serves as a centralized service registry.</p><p>Kubernetes makes service discovery in a slightly different way.</p><p>As we already mentioned, the construct that gives workloads stable IPs is <code>Services</code>.
When you create a <code>Service</code>, it gets a stable IP and a domain name that is valid inside the Kubernetes cluster.
All workloads running in that cluster can access that <code>Service</code>(and the Pods behind it) by its IP OR domain name.</p><h3 id=pid-namespace-sharinghttpskubernetesiodocstasksconfigure-pod-containershare-process-namespace><a href=https://kubernetes.io/docs/tasks/configure-pod-container/share-process-namespace/>PID namespace sharing</a></h3><p>When running containers, they share the host Kernel, but at the same time, they are isolated from one another via cgroups and <strong>namespaces</strong>.
PID Namespaces mean “Process ID Namespaces.”
Each container has its own process namespaces, which means that one container cannot see the processes run by another container (even though they are running on the same host).</p><p>The same applies when running multiple containers in a Pod - they are isolated on the namespace level and do not see each other&rsquo;s processes.</p><p>However, Kubernetes gives you the capability to make containers in the same Pod share the process namespaces (hence be able to see each other&rsquo;s processes).</p><p>This can be done via setting a simple flag in the Pod spec - <code>shareProcessNamespace</code> to <code>true</code>.</p><p>Sharing the process namespace has several use-cases.
For example, if you are deploying a sidecar that needs to be tightly integrated with the main container.
Or, for debugging purposes - you can deploy a workload container that is stripped out of all the debugging tools and then run a sidecar container that has all the utilities you need and make them share the process namespace so that you can use the second container to debug the first one.</p><h3 id=hard-and-soft-evictions>Hard and Soft Evictions</h3><p><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/node-pressure-eviction/>Evictions</a> in Kubernetes mean that the <code>kube-scheduler</code> has removed a Pod from a Node.
This can happen because the Node has gone over capacity on CPU, disk, or memory.</p><p>When starting the <code>kube-scheduler</code>, you can configure hard and soft eviction thresholds, which will tell Kubernetes under what conditions to perform the evictions.</p><h4 id=soft-evictions>Soft Evictions</h4><p>Soft evictions mean that Kubernetes will give the Pods some grace period before terminating them.
That period is configured via the <code>eviction-soft-grace-period</code> and <code>eviction-max-pod-grace-period</code> flags.</p><p>The conditions under which a soft eviction is done are configured via the <code>eviction-soft</code> property.
For example, <code>memory.available&lt;1.5Gi</code> value for the <code>eviction-soft</code> configuration means that Kubernetes will perform a soft eviction of a Pod if the available memory of a Node goes below 1.5 GB.</p><h4 id=hard-evictions>Hard Evictions</h4><p>Hard evictions mean that Kubernetes will instantly terminate the Pods without any grace period.
This is meant to happen in extreme cases where the Node&rsquo;s resources are at such a low level that something must be done immediately; otherwise, the whole Node will fail.</p><p>The conditions under which a hard eviction is done are configured via the <code>eviction-hard</code> property.</p><h3 id=evictions-api-pdbhttpskubernetesiodocsconceptsscheduling-evictionapi-eviction><a href=https://kubernetes.io/docs/concepts/scheduling-eviction/api-eviction/>Evictions API (PDB)</a></h3><p>Apart from the <code>kube-scheduler</code> performing an eviction based on some conditions, you can also evict a pod manually by calling the Evictions API.</p><p>Doing this is as simple as POST-ing an <code>Eviction</code> object to your Kube API Server:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>curl -v -H <span style=color:#2aa198>&#39;Content-type: application/json&#39;</span> https://&lt;KUBE_API_SERVER&gt;/api/v1/namespaces/default/pods/&lt;POD_NAME&gt;/eviction -d @eviction.json
</span></span></code></pre></div><p>where <code>evictions.json</code> contains the <code>Eviction</code> object:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-json data-lang=json><span style=display:flex><span>{
</span></span><span style=display:flex><span>  <span style=color:#268bd2>&#34;apiVersion&#34;</span>: <span style=color:#2aa198>&#34;policy/v1&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#268bd2>&#34;kind&#34;</span>: <span style=color:#2aa198>&#34;Eviction&#34;</span>,
</span></span><span style=display:flex><span>  <span style=color:#268bd2>&#34;metadata&#34;</span>: {
</span></span><span style=display:flex><span>    <span style=color:#268bd2>&#34;name&#34;</span>: <span style=color:#2aa198>&#34;&lt;POD_NAME&gt;&#34;</span>,
</span></span><span style=display:flex><span>    <span style=color:#268bd2>&#34;namespace&#34;</span>: <span style=color:#2aa198>&#34;&lt;NAMESPACE_NAME&gt;&#34;</span>
</span></span><span style=display:flex><span>  }
</span></span><span style=display:flex><span>}
</span></span></code></pre></div><p>or you can apply this YAML object via <code>kubectl</code>:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-bash data-lang=bash><span style=display:flex><span>kubectl apply -f eviction.yaml
</span></span></code></pre></div><p>Where <code>eviction.yaml</code> contains the <code>Eviction</code> object:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span><span style=color:#268bd2>apiVersion</span>: policy/v1
</span></span><span style=display:flex><span><span style=color:#268bd2>kind</span>: Eviction
</span></span><span style=display:flex><span><span style=color:#268bd2>metadata</span>:
</span></span><span style=display:flex><span>  <span style=color:#268bd2>name</span>: &lt;POD_NAME&gt;
</span></span><span style=display:flex><span>  <span style=color:#268bd2>namespace</span>: &lt;NAMESPACE_NAME&gt;
</span></span></code></pre></div><p>Another alternative is to use <code>kubectl drain</code> command, which will do the same, or <code>kubectl delete Pod &lt;POD_NAME> -n &lt;NAMESPACE_NAME></code>.</p><p>In all these examples, <code>&lt;POD_NAME></code> represents the name of the Pod you want to evict, and <code>&lt;NAMESPACE_NAME></code> is the namespace in which this Pod lives.</p><p>All of them will result in the same thing: the Pod being evicted from the Node.</p><h3 id=prometheus>Prometheus</h3><p><a href=https://prometheus.io/>Prometheus</a> is an open-source monitoring and alerting toolkit.
Built originally in SoundCloud, it is now under the hat of the CNCF (Cloud Native Computing Foundation).</p><p>It allows metrics collection via a pull model over HTTP.</p><p>There are various adapters that allow you to collect different types of metrics without doing much work by installing the adaptor and configuring it.
There are also libraries for various programming languages that will enable you to collect custom metrics in your application without writing much code.</p><p>Prometheus has become the de-facto standard for metric collections, and you can use it to monitor your application running and Kubernetes AND your Kubernetes clusters themselves.</p><p>To visualize that data, you can use …</p><h3 id=grafana>Grafana</h3><p><a href=https://grafana.com/>Grafana</a> is an open-source tool for visualizing data.
It allows you to build a custom dashboard for every time of metric you have.</p><p>It supports data from multiple sources, including Prometheus, MySQL, PostgreSQL, etc.</p><p>You can deploy it and manage it yourself or use the SaaS offering by Grafana at <a href=https://grafana.com/>https://grafana.com/</a>.</p><h3 id=promql>PromQL</h3><p><a href=https://prometheus.io/docs/prometheus/latest/querying/basics/><strong>PromQL</strong></a> stands for <strong>Prom</strong>etheus <strong>Q</strong>uery <strong>L</strong>anguage.
It is a structured query language that allows you to select and aggregate time-series data stored in Prometheus in real-time.</p><p>The simplest PQL expression would be something like:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>http_requests_total
</span></span></code></pre></div><p>This expression will return all-time series data for the <code>http_requests_total</code> metric.</p><p>If you want to filter by <code>job</code> and <code>handler</code> labels, you can extend the query like this:</p><div class=highlight><pre tabindex=0 style=color:#93a1a1;background-color:#002b36;-moz-tab-size:4;-o-tab-size:4;tab-size:4><code class=language-yaml data-lang=yaml><span style=display:flex><span>http_requests_total{job=&#34;apiserver&#34;, handler=&#34;/api/comments&#34;}
</span></span></code></pre></div><p>The language supports many complex expressions and functions like <code>rate</code>, <code>sum by</code>, etc.</p><p>For complete language reference, check the <a href=https://prometheus.io/docs/prometheus/latest/querying/basics/>docs</a> and <a href=https://prometheus.io/docs/prometheus/latest/querying/examples/>examples</a>.</p><h3 id=health-checks>Health checks</h3><p>A <a href=https://kubernetes.io/docs/tasks/configure-pod-container/configure-liveness-readiness-startup-probes/>health check</a> is an action that is performed to determine whether a given Pod is healthy and can service requests.</p><p>When creating a Pod, you can define “probes,” e.g., actions that Kubernetes will execute to determine the application&rsquo;s state.</p><p>There are three types of probes:</p><h4 id=startup-probes>Startup probes</h4><p>A startup probe is defined to indicate Kubernetes when the application has started.</p><p>All other probes are disabled until the startup probes have been executed successfully.</p><p>Defined via the <code>spec.startupProbe</code> field in the Pod spec.</p><h4 id=liveness-probes>Liveness probes</h4><p>A liveness probe indicates whether the container is healthy.
If not, it will be restarted.</p><p>A liveness probe is configured via the <code>spec.livenessProbe</code> field in the Pod spec.</p><p>There are a few types of liveness probes - HTTP(<code>livenessProbe.httpGet</code>), TCP (<code>livenessProbe.tcpSocket</code>), gRPC (<code>livenessProbe.grpc</code>) or command (<code>livenessProbe.exec</code>).</p><p>Kubernetes will perform the action defined in the liveness probe (for example, make an HTTP GET request to an endpoint) to determine whether the application is healthy.</p><p>If a few consecutive liveness probes fail, Kubernetes will consider the Pod not healthy and restart it.
The number of probes needed to fail before Kubernetes does that is configured via the <code>livenessProbe.failureThreshold</code> field.</p><p>There are other specifics to these probes like:</p><ul><li>if a startup probe is defined, Kubernetes will wait for that to succeed before starting to try to liveness probe.
Otherwise, there is the possibility that Kubernetes will be restarting Pods that have not even started because of failing liveness probes.</li><li>You can also configure how often Kubernetes will check the liveness probe via the <code>periodSeconds</code> property.</li><li>You can configure how much time after the container has started to wait before calling the probes via the <code>initialDelaySeconds</code> property.</li></ul><p>For full API reference of the probes, check the <a href=https://kubernetes.io/docs/reference/generated/kubernetes-api/v1.19/#probe-v1-core>API docs</a>.</p><h4 id=readiness-probes>Readiness probes</h4><p>Similar to liveness probes, but shows whether the Pod is ready to serve requests or not.</p><p>If a liveness probe fails, the Pod will be restarted.
If a Readiness probe fails, the Pod will not be restarted but will be removed from the Service load balancer (so that it does not serve requests).</p><p>Defined via the <code>spec.readinessProbe</code> field in the Pod spec.</p><p>All configuration options for the liveness probe are also valid for the readiness probes.</p><h3 id=terraform>Terraform</h3><p><a href=https://www.terraform.io/>Terraform</a> is an open-source tool that allows you to describe your infrastructure in Terraform files and create/update it via a simple command.
This is the so-called IaC or Infrastructure as Code.</p><p>It supports multiple cloud providers via so-called Terraform providers.
For example, you can use the AWS provider for AWS resources, the Azure provider for Azure resources, etc.</p><p>By doing this, you can manage your infrastructure in a centralized manner via the GitOps approach.
You can keep your Terraform files in a git repo.
Each time someone wants to make a change to your infrastructure (for example, create a new Kubernetes cluster or a new Virtual Machine), they need to make a change to the Terraform files, commit that, and open a Pull Requests, get that reviewed and approved and merge it.
Once merged, the CI/CD pipelines will take care of running the Terraform command that will create the new resources.</p><p>Not using such solutions would mean that someone needs to manually go and use the cloud provider UI to create new resources.
This has many drawbacks.
For example:</p><ul><li>you have to do this once for each environment you have.
e.g., if you have dev, test, and prod environments, you would have to do this action three times, once for each environment.
With Terraform, you can reuse one set of files for one environment.</li><li>The person that does this cannot get his work verified by a team member in an easy way.
e.g., how do you make sure that the person doing this would create the right resources? With Terraform and GitOps, all changes are reviewed before merging to the main branch and applied.</li><li>Without Terraform, you have no easy way of tracking ALL of your infrastructures.
This can be a problem if you have three environments but want to create a 4th one.
How do you ensure you have not missed creating some resources in the new environment? You can&rsquo;t.
You don&rsquo;t have that problem with Terraform because your whole environment is described in the Terraform files.</li></ul><p>Other IaC projects provide alternatives to Terraform.
These include, but are not limited to <a href=https://www.pulumi.com/>Pulumi</a>, <a href=https://aws.amazon.com/cloudformation/>AWS Cloud Formations</a> (only for AWS resources), <a href=https://docs.microsoft.com/en-us/azure/azure-resource-manager/templates/overview>Azure Resource Templates</a> (only for Azure resources), and so on.</p><h3 id=qos-cgroups-oom_score_adj>QoS (cgroups, oom_score_adj)</h3><p><a href=https://kubernetes.io/docs/tasks/configure-pod-container/quality-service-pod/>QoS</a> stands for Quality of Service.</p><p>In Kubernetes, QoS classes are a property that Kubernetes will assign to your Pods depending on their resource limits configuration.</p><p>The QoS classes are:</p><h4 id=guaranteed>Guaranteed</h4><p>The <code>Guaranteed</code> QoS class is assigned to Pods that satisfy these conditions:</p><ul><li>Every Container in the Pod has a memory limit and a memory request</li><li>For every container in the Pod, the memory limit is equal to the memory request.</li><li>Every Container in the Pod has a CPU limit and a CPU request.</li><li>For every container in the Pod, the CPU limit is equal to the CPU request.</li></ul><h4 id=burstable>Burstable</h4><p>The <code>Burstable</code> QoS class is assigned to Pods that do not satisfy the conditions for <code>Guaranteed</code> but satisfy this condition:</p><ul><li>At least one container in the Pod has a memory or CPU request or limit</li></ul><h4 id=besteffort>BestEffort</h4><p>The <code>BestEffort</code> QoS class is assigned to Pods whose containers don&rsquo;t have any memory or CPU limits or requests.</p><h3 id=hpavpa-based-on-custom-metrics>HPA/VPA based on custom metrics</h3><p>In <a href=http://localhost:1313/blog/2022/05/22/demystifying-the-kubernetes-iceberg-part-2/#hpa>the last article</a>, I explained what HPA is and how to do it with Kubernetes-defined metrics.</p><p>Another thing you can do is define your custom metrics, which can be used by the HPA to determine when you scale out/in.</p><p>This is enabled by tools like the <a href=https://github.com/kubernetes-sigs/metrics-server>metrics-server</a> that expose custom metrics to the Metrics API.
These metrics are then used by the HPA (which is configured to look at them) to determine whether a workload needs scaling.</p><p>Apart from the HorizontalPodAutoscaler which we talked about in the last article, there is also the Vertical Pod Autoscaler.
Vertical scaling means that instead of creating new instances of our workloads, we increase the resources of our existing ones (e.g.
we provide more memory, CPU, and disk).</p><p>With VPA you don&rsquo;t need to set resource limits to your workloads, instead, the VPA will set them and adjust them accordingly.</p><p>The VPA also supports custom metrics.</p><h2 id=summary>Summary</h2><p>This is all for part three.</p><p>With this article we already go into a deep territory and into concepts which you don&rsquo;t necessary use on a day-to-day basis.
I hope these articles are useful to you and you are learning something new.
I definitely am while working on them!</p><p>The series continues with <a href=/blog/2022/06/05/demystifying-the-kubernetes-iceberg-part-4/>Part 4</a>.</p><p>If you don’t want to miss it, you can follow me on <a href=https://twitter.com/a_sankov>Twitter</a> or <a href=https://www.linkedin.com/in/asankov/>LinkedIn</a>.</p><ul class="list-unstyled d-flex justify-content-between align-items-center mb-0 pt-5"><li><a href=/blog/2022/05/22/demystifying-the-kubernetes-iceberg-part-2/ aria-label="Previous - Demystifying the Kubernetes Iceberg: Part 2" class="btn btn-primary"><span class=mr-1>←</span>Previous</a></li><a href=/blog/2022/06/05/demystifying-the-kubernetes-iceberg-part-4/ aria-label="Next - Demystifying the Kubernetes Iceberg: Part 4" class="btn btn-primary">Next<span class=ml-1>→</span></a></li></ul></div></main></div></div><footer class="py-5 row d-print-none bg-nord0"><div class="container-fluid mx-sm-5"><div class=row><div class="col-6 col-sm-4 text-xs-center order-sm-2"><ul class="list-inline mb-0"><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title="User mailing list" aria-label="User mailing list"><a class=text-white target=_blank rel=noopener href=mailto:asankov96@gmail.com aria-label="User mailing list"><i class="fa fa-envelope"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=Twitter aria-label=Twitter><a class=text-white target=_blank rel=noopener href=https://twitter.com/a_sankov aria-label=Twitter><i class="fab fa-twitter"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=GitHub aria-label=GitHub><a class=text-white target=_blank rel=noopener href=https://github.com/asankov aria-label=GitHub><i class="fab fa-github"></i></a></li><li class="list-inline-item mx-2 h3" data-toggle=tooltip data-placement=top title=LinkedIn aria-label=LinkedIn><a class=text-white target=_blank rel=noopener href=https://linkedin.com/in/asankov aria-label=LinkedIn><i class="fab fa-linkedin"></i></a></li></ul></div><div class="col-6 col-sm-4 text-right text-xs-center order-sm-3"></div><div class="col-12 col-sm-4 text-center py-2 order-sm-2"><small class=text-white>&copy; 2022 Anton Sankov All Rights Reserved</small>
<small class=ml-1><a href=https://policies.google.com/privacy target=_blank rel=noopener>Privacy Policy</a></small><p class=mt-2><a href=/about/>About Me</a></p></div></div></div></footer></div><script src=https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js integrity=sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN crossorigin=anonymous></script>
<script src=https://cdn.jsdelivr.net/npm/bootstrap@4.6.1/dist/js/bootstrap.min.js integrity="sha512-UR25UO94eTnCVwjbXozyeVd6ZqpaAE9naiEUBK/A+QDbfSTQFhPGj5lOR6d8tsgbBk84Ggb5A3EkjsOgPRPcKA==" crossorigin=anonymous></script>
<script src=/js/tabpane-persist.js></script>
<script src=/js/main.min.1f7a9a77f4986d1b3c8c9d4e576bc7675ba7359139a0f97729bd28e9e2e1fd49.js integrity="sha256-H3qad/SYbRs8jJ1OV2vHZ1unNZE5oPl3Kb0o6eLh/Uk=" crossorigin=anonymous></script></body></html>